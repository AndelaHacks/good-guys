import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import re
import seaborn as sb
%matplotlib inline
%config InlineBackend.figure_format = 'retina'

df  = pd.read_csv("data.csv")
df.head()
df.Headline.unique()
df.shape


from bs4 import BeautifulSoup
import requests

news_url="https://news.google.com/news/rss"
response = requests.get(news_url, timeout=5)
content = BeautifulSoup(response.content, "html.parser")
news_list = content.find_all("item")


for news in news_list:
  print(news.title.text)
  print("-"*60)
  print (news.text)
  print("-"*60)

import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('brown')
nltk.download('inaugural')
from nltk import word_tokenize
tokens = word_tokenize(raw)
text = nltk.Text(tokens)
tokens
text.collocations()



tokens = tokens[100:50000]
text = nltk.Text(tokens)
text.concordance('a')



#content = news.text
#print(content[:70])

#raw = BeautifulSoup(content).get_text()
#word_tokenize(raw)

import nltk
#from nltk.tokenize import word_tokenize
from nltk.corpus import brown

cfd = nltk.ConditionalFreqDist(
          (genre, word)
          for genre in brown.categories()
          for word in brown.words(categories=genre))
categories = ['politics', 'business','celebrity', 'sports']
searchwords = [ 'breaking news', 'n-word', 'Trump', 'Obama', 'Migrants', 'Refugees']
cfd.tabulate(conditions=categories, samples=searchwords)


from nltk.corpus import inaugural
cfd = nltk.ConditionalFreqDist(
           (target, fileid[:4])
          for fileid in inaugural.fileids()
           for w in inaugural.words(fileid)
           for target in ['breaking news', 'n-word', 'Trump', 'Obama', 'Migrants', 'Refugees']
           if w.lower().startswith(target)) [1]
cfd.plot()
